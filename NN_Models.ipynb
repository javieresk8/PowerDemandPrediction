{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "753f1056",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5baf2bc5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AÑO</th>\n",
       "      <th>MES</th>\n",
       "      <th>DIA</th>\n",
       "      <th>FECHA</th>\n",
       "      <th>HORA</th>\n",
       "      <th>KW-H</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>jueves</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>jueves</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>jueves</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>jueves</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>jueves</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43819</th>\n",
       "      <td>2019</td>\n",
       "      <td>12</td>\n",
       "      <td>martes</td>\n",
       "      <td>31</td>\n",
       "      <td>19</td>\n",
       "      <td>3400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43820</th>\n",
       "      <td>2019</td>\n",
       "      <td>12</td>\n",
       "      <td>martes</td>\n",
       "      <td>31</td>\n",
       "      <td>20</td>\n",
       "      <td>3600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43821</th>\n",
       "      <td>2019</td>\n",
       "      <td>12</td>\n",
       "      <td>martes</td>\n",
       "      <td>31</td>\n",
       "      <td>21</td>\n",
       "      <td>3800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43822</th>\n",
       "      <td>2019</td>\n",
       "      <td>12</td>\n",
       "      <td>martes</td>\n",
       "      <td>31</td>\n",
       "      <td>22</td>\n",
       "      <td>4000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43823</th>\n",
       "      <td>2019</td>\n",
       "      <td>12</td>\n",
       "      <td>martes</td>\n",
       "      <td>31</td>\n",
       "      <td>23</td>\n",
       "      <td>4000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>43824 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        AÑO  MES     DIA  FECHA  HORA  KW-H\n",
       "0      2015    1  jueves      1     0  3200\n",
       "1      2015    1  jueves      1     1  3200\n",
       "2      2015    1  jueves      1     2  2400\n",
       "3      2015    1  jueves      1     3  2400\n",
       "4      2015    1  jueves      1     4  2400\n",
       "...     ...  ...     ...    ...   ...   ...\n",
       "43819  2019   12  martes     31    19  3400\n",
       "43820  2019   12  martes     31    20  3600\n",
       "43821  2019   12  martes     31    21  3800\n",
       "43822  2019   12  martes     31    22  4000\n",
       "43823  2019   12  martes     31    23  4000\n",
       "\n",
       "[43824 rows x 6 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Lectura de datos \n",
    "data = pd.read_csv('DEPURACION_FINAL.csv', sep=',')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f834942",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AÑO      0\n",
       "MES      0\n",
       "DIA      0\n",
       "FECHA    0\n",
       "HORA     0\n",
       "KW-H     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Verificacion de nans \n",
    "data.isnull().values.any()\n",
    "data.isnull().sum().sum()\n",
    "\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f2d0cb09",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AÑO</th>\n",
       "      <th>MES</th>\n",
       "      <th>DIA</th>\n",
       "      <th>FECHA</th>\n",
       "      <th>HORA</th>\n",
       "      <th>KW-H</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>2400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>2600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>2600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>2600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>2600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>2600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>2600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>2600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>2600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>2300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>2300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>2300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>2300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>2400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>2400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>2400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>2200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>2200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>2200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>2200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>2200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>2200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>2200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>3100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>3400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>3400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>3400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>3300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>3700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "      <td>3700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>3700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>21</td>\n",
       "      <td>3700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "      <td>2900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>2700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     AÑO  MES  DIA  FECHA  HORA  KW-H\n",
       "0   2015    1    4      1     0  3200\n",
       "1   2015    1    4      1     1  3200\n",
       "2   2015    1    4      1     2  2400\n",
       "3   2015    1    4      1     3  2400\n",
       "4   2015    1    4      1     4  2400\n",
       "5   2015    1    4      1     5  2400\n",
       "6   2015    1    4      1     6  2400\n",
       "7   2015    1    4      1     7  2400\n",
       "8   2015    1    4      1     8  2400\n",
       "9   2015    1    4      1     9  2600\n",
       "10  2015    1    4      1    10  2600\n",
       "11  2015    1    4      1    11  2600\n",
       "12  2015    1    4      1    12  2600\n",
       "13  2015    1    4      1    13  2600\n",
       "14  2015    1    4      1    14  2600\n",
       "15  2015    1    4      1    15  2600\n",
       "16  2015    1    4      1    16  2600\n",
       "17  2015    1    4      1    17  2300\n",
       "18  2015    1    4      1    18  2300\n",
       "19  2015    1    4      1    19  2300\n",
       "20  2015    1    4      1    20  2300\n",
       "21  2015    1    4      1    21  2400\n",
       "22  2015    1    4      1    22  2400\n",
       "23  2015    1    4      1    23  2400\n",
       "24  2015    1    5      2     0  2400\n",
       "25  2015    1    5      2     1  2400\n",
       "26  2015    1    5      2     2  2400\n",
       "27  2015    1    5      2     3  2400\n",
       "28  2015    1    5      2     4  2200\n",
       "29  2015    1    5      2     5  2200\n",
       "30  2015    1    5      2     6  2200\n",
       "31  2015    1    5      2     7  2200\n",
       "32  2015    1    5      2     8  2200\n",
       "33  2015    1    5      2     9  2200\n",
       "34  2015    1    5      2    10  2200\n",
       "35  2015    1    5      2    11  2200\n",
       "36  2015    1    5      2    12  2200\n",
       "37  2015    1    5      2    13  3100\n",
       "38  2015    1    5      2    14  3400\n",
       "39  2015    1    5      2    15  3400\n",
       "40  2015    1    5      2    16  3400\n",
       "41  2015    1    5      2    17  3300\n",
       "42  2015    1    5      2    18  3700\n",
       "43  2015    1    5      2    19  3700\n",
       "44  2015    1    5      2    20  3700\n",
       "45  2015    1    5      2    21  3700\n",
       "46  2015    1    5      2    22  2900\n",
       "47  2015    1    5      2    23  2700\n",
       "48  2015    1    6      3     0  2500\n",
       "49  2015    1    6      3     1  2500"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Variable categrica DIA a numérica\n",
    "data['DIA'] = data['DIA'].map({'lunes': 1 ,\n",
    "                                           'martes': 2,\n",
    "                                           'miercoles': 3,\n",
    "                                           'miércoles': 3,\n",
    "                                           'jueves': 4 , \n",
    "                                           'viernes': 5, \n",
    "                                           'sábado': 6,\n",
    "                                           'sabado': 6,  #inconsistencia en la data por las tildes\n",
    "                                           'domingo': 7})\n",
    "\n",
    "data.head(50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ff00b77c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AÑO      2018.0\n",
       "MES         1.0\n",
       "DIA         1.0\n",
       "FECHA       1.0\n",
       "HORA        2.0\n",
       "KW-H        4.1\n",
       "Name: 26306, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Transformacion de datos a numerica\n",
    "\n",
    "data['KW-H'] = [valor.replace(\",\", \".\") for valor in data['KW-H'] ]\n",
    "data['KW-H'] = [float(valor) for valor in data['KW-H'] ]\n",
    "data.iloc[26306, :]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "59ba345c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Dividir los datos de entrenamiento y de test, 80/20\n",
    "x = data.iloc[:,:-1]\n",
    "y = data.iloc[:,-1]\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.20, random_state = 30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "224a52ff",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(35059, 5)\n",
      "(8765, 5)\n",
      "(35059,)\n",
      "(8765,)\n",
      "AÑO      0\n",
      "MES      0\n",
      "DIA      0\n",
      "FECHA    0\n",
      "HORA     0\n",
      "KW-H     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "print(data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "846855df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 7.04547816e-01, -7.30349773e-01,  4.98924639e-01,\n",
       "        -3.14982389e-01,  1.22628325e+00],\n",
       "       [ 7.04547816e-01,  1.30168126e+00, -7.11651507e-05,\n",
       "        -1.67780697e+00, -5.06949654e-01],\n",
       "       [-2.46028089e-03, -4.40059626e-01, -9.98062773e-01,\n",
       "        -1.56423825e+00,  2.15230722e-01],\n",
       "       ...,\n",
       "       [ 7.04547816e-01,  1.01139111e+00, -7.11651507e-05,\n",
       "         2.52861186e-01, -1.08469395e+00],\n",
       "       [-1.41647648e+00,  1.40520668e-01, -4.99066969e-01,\n",
       "        -8.82825964e-01, -9.40257879e-01],\n",
       "       [ 1.41155591e+00, -1.49769479e-01,  9.97920443e-01,\n",
       "        -1.67780697e+00, -9.40257879e-01]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Escalamiento de datso con StandardScaler\n",
    "#En vista de loss nan \n",
    "from sklearn.preprocessing import StandardScaler \n",
    "scaler = StandardScaler()\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_test = scaler.fit_transform(x_test)\n",
    "x_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "49b12a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Crear el modelo \n",
    "model = Sequential()\n",
    "#Capa de entrada y primera capa oculta\n",
    "model.add(Dense(1024, input_dim = 5, activation= \"relu\"))\n",
    "# model.add(Dense(1))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.1))\n",
    "\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.1))\n",
    "\n",
    "model.add(Dense(256))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(1))\n",
    "\n",
    "# sgd = SGD(lr=0.01, nesterov=True); NAN\n",
    "model.compile(optimizer = 'adam', loss = \"mean_squared_error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5f556c75",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "35059/35059 [==============================] - 18s 502us/step - loss: 1769365.4137\n",
      "Epoch 2/100\n",
      "35059/35059 [==============================] - 18s 522us/step - loss: 1428633.6646\n",
      "Epoch 3/100\n",
      "35059/35059 [==============================] - 19s 529us/step - loss: 1402395.3742\n",
      "Epoch 4/100\n",
      "35059/35059 [==============================] - 18s 521us/step - loss: 1276532.7661\n",
      "Epoch 5/100\n",
      "35059/35059 [==============================] - 18s 502us/step - loss: 1129348.7666\n",
      "Epoch 6/100\n",
      "35059/35059 [==============================] - 18s 499us/step - loss: 964557.4403\n",
      "Epoch 7/100\n",
      "35059/35059 [==============================] - 17s 494us/step - loss: 894137.0098\n",
      "Epoch 8/100\n",
      "35059/35059 [==============================] - 17s 498us/step - loss: 853342.6636\n",
      "Epoch 9/100\n",
      "35059/35059 [==============================] - 18s 499us/step - loss: 828502.7363\n",
      "Epoch 10/100\n",
      "35059/35059 [==============================] - 17s 494us/step - loss: 795511.3121\n",
      "Epoch 11/100\n",
      "35059/35059 [==============================] - 18s 517us/step - loss: 766092.5762\n",
      "Epoch 12/100\n",
      "35059/35059 [==============================] - 17s 491us/step - loss: 727996.2259\n",
      "Epoch 13/100\n",
      "35059/35059 [==============================] - 18s 504us/step - loss: 689235.7216\n",
      "Epoch 14/100\n",
      "35059/35059 [==============================] - 17s 492us/step - loss: 628640.6603\n",
      "Epoch 15/100\n",
      "35059/35059 [==============================] - 20s 567us/step - loss: 580329.8557\n",
      "Epoch 16/100\n",
      "35059/35059 [==============================] - 19s 531us/step - loss: 551564.0187\n",
      "Epoch 17/100\n",
      "35059/35059 [==============================] - 17s 495us/step - loss: 512472.6477\n",
      "Epoch 18/100\n",
      "35059/35059 [==============================] - 17s 481us/step - loss: 483878.0041\n",
      "Epoch 19/100\n",
      "35059/35059 [==============================] - 17s 497us/step - loss: 463005.1547\n",
      "Epoch 20/100\n",
      "35059/35059 [==============================] - 17s 493us/step - loss: 442794.5224\n",
      "Epoch 21/100\n",
      "35059/35059 [==============================] - 17s 497us/step - loss: 426373.4467\n",
      "Epoch 22/100\n",
      "35059/35059 [==============================] - 17s 497us/step - loss: 416533.0763\n",
      "Epoch 23/100\n",
      "35059/35059 [==============================] - 17s 495us/step - loss: 403560.8615\n",
      "Epoch 24/100\n",
      "35059/35059 [==============================] - 17s 499us/step - loss: 397201.0178\n",
      "Epoch 25/100\n",
      "35059/35059 [==============================] - 17s 492us/step - loss: 383453.5995\n",
      "Epoch 26/100\n",
      "35059/35059 [==============================] - 18s 523us/step - loss: 380339.3688\n",
      "Epoch 27/100\n",
      "35059/35059 [==============================] - 19s 535us/step - loss: 371734.9573\n",
      "Epoch 28/100\n",
      "35059/35059 [==============================] - 18s 511us/step - loss: 363776.4602\n",
      "Epoch 29/100\n",
      "35059/35059 [==============================] - 17s 487us/step - loss: 356112.2172\n",
      "Epoch 30/100\n",
      "35059/35059 [==============================] - 17s 486us/step - loss: 352848.2096\n",
      "Epoch 31/100\n",
      "35059/35059 [==============================] - 17s 499us/step - loss: 344765.6053\n",
      "Epoch 32/100\n",
      "35059/35059 [==============================] - 17s 482us/step - loss: 342792.1099\n",
      "Epoch 33/100\n",
      "35059/35059 [==============================] - 17s 495us/step - loss: 337320.8449\n",
      "Epoch 34/100\n",
      "35059/35059 [==============================] - 17s 487us/step - loss: 332278.5938\n",
      "Epoch 35/100\n",
      "35059/35059 [==============================] - 17s 485us/step - loss: 325471.5441\n",
      "Epoch 36/100\n",
      "35059/35059 [==============================] - 17s 489us/step - loss: 322070.4507\n",
      "Epoch 37/100\n",
      "35059/35059 [==============================] - 18s 505us/step - loss: 315311.7461\n",
      "Epoch 38/100\n",
      "35059/35059 [==============================] - 19s 532us/step - loss: 313098.8092\n",
      "Epoch 39/100\n",
      "35059/35059 [==============================] - 21s 606us/step - loss: 311635.7477\n",
      "Epoch 40/100\n",
      "35059/35059 [==============================] - 21s 604us/step - loss: 305640.8485\n",
      "Epoch 41/100\n",
      "35059/35059 [==============================] - 20s 580us/step - loss: 301893.0283\n",
      "Epoch 42/100\n",
      "35059/35059 [==============================] - 20s 559us/step - loss: 298443.3095\n",
      "Epoch 43/100\n",
      "35059/35059 [==============================] - 19s 550us/step - loss: 298648.5510\n",
      "Epoch 44/100\n",
      "35059/35059 [==============================] - 20s 560us/step - loss: 290596.9899\n",
      "Epoch 45/100\n",
      "35059/35059 [==============================] - 17s 496us/step - loss: 287131.0250\n",
      "Epoch 46/100\n",
      "35059/35059 [==============================] - 18s 515us/step - loss: 282526.0396\n",
      "Epoch 47/100\n",
      "35059/35059 [==============================] - 18s 521us/step - loss: 283985.5203\n",
      "Epoch 48/100\n",
      "35059/35059 [==============================] - 18s 509us/step - loss: 281564.3588\n",
      "Epoch 49/100\n",
      "35059/35059 [==============================] - 18s 513us/step - loss: 278714.1801\n",
      "Epoch 50/100\n",
      "35059/35059 [==============================] - 17s 494us/step - loss: 275496.1895\n",
      "Epoch 51/100\n",
      "35059/35059 [==============================] - 18s 506us/step - loss: 269749.2067\n",
      "Epoch 52/100\n",
      "35059/35059 [==============================] - 19s 554us/step - loss: 271875.0128\n",
      "Epoch 53/100\n",
      "35059/35059 [==============================] - 18s 519us/step - loss: 268719.1248\n",
      "Epoch 54/100\n",
      "35059/35059 [==============================] - 18s 508us/step - loss: 265615.5902\n",
      "Epoch 55/100\n",
      "35059/35059 [==============================] - 18s 517us/step - loss: 262895.4888\n",
      "Epoch 56/100\n",
      "35059/35059 [==============================] - 18s 502us/step - loss: 260211.7639\n",
      "Epoch 57/100\n",
      "35059/35059 [==============================] - 17s 488us/step - loss: 257326.7194\n",
      "Epoch 58/100\n",
      "35059/35059 [==============================] - 17s 483us/step - loss: 255646.1494\n",
      "Epoch 59/100\n",
      "35059/35059 [==============================] - 17s 487us/step - loss: 256495.4063\n",
      "Epoch 60/100\n",
      "35059/35059 [==============================] - 18s 513us/step - loss: 252434.4210\n",
      "Epoch 61/100\n",
      "35059/35059 [==============================] - 19s 542us/step - loss: 252532.0442\n",
      "Epoch 62/100\n",
      "35059/35059 [==============================] - 17s 490us/step - loss: 249695.9969\n",
      "Epoch 63/100\n",
      "35059/35059 [==============================] - 18s 506us/step - loss: 247803.8654\n",
      "Epoch 64/100\n",
      "35059/35059 [==============================] - 17s 488us/step - loss: 246184.7603\n",
      "Epoch 65/100\n",
      "35059/35059 [==============================] - 18s 513us/step - loss: 242346.1263\n",
      "Epoch 66/100\n",
      "35059/35059 [==============================] - 17s 499us/step - loss: 241727.7572\n",
      "Epoch 67/100\n",
      "35059/35059 [==============================] - 18s 503us/step - loss: 237926.0692\n",
      "Epoch 68/100\n",
      "35059/35059 [==============================] - 17s 488us/step - loss: 240437.6796\n",
      "Epoch 69/100\n",
      "35059/35059 [==============================] - 18s 508us/step - loss: 240631.1047\n",
      "Epoch 70/100\n",
      "35059/35059 [==============================] - 18s 504us/step - loss: 236042.5454\n",
      "Epoch 71/100\n",
      "35059/35059 [==============================] - 18s 507us/step - loss: 234974.2057\n",
      "Epoch 72/100\n",
      "35059/35059 [==============================] - 17s 496us/step - loss: 234367.9149\n",
      "Epoch 73/100\n",
      "35059/35059 [==============================] - 17s 494us/step - loss: 233359.6849\n",
      "Epoch 74/100\n",
      "35059/35059 [==============================] - 17s 492us/step - loss: 231379.8551\n",
      "Epoch 75/100\n",
      "35059/35059 [==============================] - 17s 473us/step - loss: 228706.5716\n",
      "Epoch 76/100\n",
      "35059/35059 [==============================] - 19s 539us/step - loss: 228477.6121\n",
      "Epoch 77/100\n",
      "35059/35059 [==============================] - 17s 497us/step - loss: 227399.5237\n",
      "Epoch 78/100\n",
      "35059/35059 [==============================] - 18s 506us/step - loss: 225691.2148\n",
      "Epoch 79/100\n",
      "35059/35059 [==============================] - 18s 508us/step - loss: 226425.8621\n",
      "Epoch 80/100\n",
      "35059/35059 [==============================] - 17s 491us/step - loss: 224643.2039\n",
      "Epoch 81/100\n",
      "35059/35059 [==============================] - 19s 548us/step - loss: 222612.8510\n",
      "Epoch 82/100\n",
      "35059/35059 [==============================] - 18s 501us/step - loss: 221151.2813\n",
      "Epoch 83/100\n",
      "35059/35059 [==============================] - 17s 496us/step - loss: 217049.6813\n",
      "Epoch 84/100\n",
      "35059/35059 [==============================] - 19s 552us/step - loss: 220087.7433\n",
      "Epoch 85/100\n",
      "35059/35059 [==============================] - 16s 469us/step - loss: 217281.9753\n",
      "Epoch 86/100\n",
      "35059/35059 [==============================] - 17s 486us/step - loss: 219618.2410\n",
      "Epoch 87/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35059/35059 [==============================] - 16s 468us/step - loss: 213522.7584\n",
      "Epoch 88/100\n",
      "35059/35059 [==============================] - 16s 468us/step - loss: 213368.9490\n",
      "Epoch 89/100\n",
      "35059/35059 [==============================] - 17s 477us/step - loss: 212038.1426\n",
      "Epoch 90/100\n",
      "35059/35059 [==============================] - 16s 459us/step - loss: 212820.2831\n",
      "Epoch 91/100\n",
      "35059/35059 [==============================] - 17s 472us/step - loss: 213645.4942\n",
      "Epoch 92/100\n",
      "35059/35059 [==============================] - 16s 468us/step - loss: 211144.5119\n",
      "Epoch 93/100\n",
      "35059/35059 [==============================] - 16s 469us/step - loss: 209776.6659\n",
      "Epoch 94/100\n",
      "35059/35059 [==============================] - 17s 479us/step - loss: 210344.8484\n",
      "Epoch 95/100\n",
      "35059/35059 [==============================] - 18s 503us/step - loss: 207651.1958\n",
      "Epoch 96/100\n",
      "35059/35059 [==============================] - 16s 463us/step - loss: 209348.4724\n",
      "Epoch 97/100\n",
      "35059/35059 [==============================] - 16s 468us/step - loss: 207740.7683\n",
      "Epoch 98/100\n",
      "35059/35059 [==============================] - 16s 469us/step - loss: 202906.5434\n",
      "Epoch 99/100\n",
      "35059/35059 [==============================] - 16s 459us/step - loss: 204757.4915\n",
      "Epoch 100/100\n",
      "35059/35059 [==============================] - 16s 466us/step - loss: 204770.8605\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f9f594f6550>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Entrenar con el algoritmo de back indicado \n",
    "model.fit(x_train, y_train, epochs = 100 , batch_size= 32)\n",
    "\n",
    "\n",
    "#Ver el error "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c6a69e6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "35059/35059 [==============================] - 7s 191us/step - loss: 9181317.8288\n",
      "Epoch 2/100\n",
      "35059/35059 [==============================] - 6s 179us/step - loss: 8404767.3721\n",
      "Epoch 3/100\n",
      "35059/35059 [==============================] - 7s 186us/step - loss: 7703320.4261\n",
      "Epoch 4/100\n",
      "35059/35059 [==============================] - 7s 187us/step - loss: 7048699.0470\n",
      "Epoch 5/100\n",
      "35059/35059 [==============================] - 6s 179us/step - loss: 6435609.2660\n",
      "Epoch 6/100\n",
      "35059/35059 [==============================] - 6s 180us/step - loss: 5860329.0794\n",
      "Epoch 7/100\n",
      "35059/35059 [==============================] - 6s 177us/step - loss: 5322739.3119\n",
      "Epoch 8/100\n",
      "35059/35059 [==============================] - 6s 184us/step - loss: 4822936.4599\n",
      "Epoch 9/100\n",
      "35059/35059 [==============================] - 7s 189us/step - loss: 4362577.3165\n",
      "Epoch 10/100\n",
      "35059/35059 [==============================] - 7s 189us/step - loss: 3935326.5667\n",
      "Epoch 11/100\n",
      "35059/35059 [==============================] - 6s 183us/step - loss: 3546687.3523\n",
      "Epoch 12/100\n",
      "35059/35059 [==============================] - 6s 180us/step - loss: 3194583.1801\n",
      "Epoch 13/100\n",
      "35059/35059 [==============================] - 6s 182us/step - loss: 2876433.2550\n",
      "Epoch 14/100\n",
      "35059/35059 [==============================] - 7s 189us/step - loss: 2597456.5315\n",
      "Epoch 15/100\n",
      "35059/35059 [==============================] - 7s 188us/step - loss: 2349112.8781\n",
      "Epoch 16/100\n",
      "35059/35059 [==============================] - 6s 179us/step - loss: 2138617.9765\n",
      "Epoch 17/100\n",
      "35059/35059 [==============================] - 6s 177us/step - loss: 1961508.9234\n",
      "Epoch 18/100\n",
      "35059/35059 [==============================] - 6s 182us/step - loss: 1814927.1117\n",
      "Epoch 19/100\n",
      "35059/35059 [==============================] - 6s 185us/step - loss: 1700670.3739\n",
      "Epoch 20/100\n",
      "35059/35059 [==============================] - 6s 183us/step - loss: 1612683.3573\n",
      "Epoch 21/100\n",
      "35059/35059 [==============================] - 6s 177us/step - loss: 1552977.9429\n",
      "Epoch 22/100\n",
      "35059/35059 [==============================] - 6s 178us/step - loss: 1491889.2791\n",
      "Epoch 23/100\n",
      "35059/35059 [==============================] - 6s 182us/step - loss: 1442955.1237\n",
      "Epoch 24/100\n",
      "35059/35059 [==============================] - 7s 187us/step - loss: 1406604.3582\n",
      "Epoch 25/100\n",
      "35059/35059 [==============================] - 7s 189us/step - loss: 1392717.6469\n",
      "Epoch 26/100\n",
      "35059/35059 [==============================] - 6s 184us/step - loss: 1371067.3135\n",
      "Epoch 27/100\n",
      "35059/35059 [==============================] - 6s 181us/step - loss: 1366739.7541\n",
      "Epoch 28/100\n",
      "35059/35059 [==============================] - 6s 180us/step - loss: 1362656.4520\n",
      "Epoch 29/100\n",
      "35059/35059 [==============================] - 6s 184us/step - loss: 1362379.6102\n",
      "Epoch 30/100\n",
      "35059/35059 [==============================] - 6s 185us/step - loss: 1360896.8822\n",
      "Epoch 31/100\n",
      "35059/35059 [==============================] - 6s 181us/step - loss: 1252200.1668\n",
      "Epoch 32/100\n",
      "35059/35059 [==============================] - 6s 180us/step - loss: 1179958.8020\n",
      "Epoch 33/100\n",
      "35059/35059 [==============================] - 6s 181us/step - loss: 1146674.4702\n",
      "Epoch 34/100\n",
      "35059/35059 [==============================] - 6s 184us/step - loss: 1119045.0889\n",
      "Epoch 35/100\n",
      "35059/35059 [==============================] - 6s 184us/step - loss: 1090064.3334\n",
      "Epoch 36/100\n",
      "35059/35059 [==============================] - 6s 184us/step - loss: 1076465.6463\n",
      "Epoch 37/100\n",
      "35059/35059 [==============================] - 6s 178us/step - loss: 1065231.3366\n",
      "Epoch 38/100\n",
      "35059/35059 [==============================] - 6s 177us/step - loss: 1055469.6677\n",
      "Epoch 39/100\n",
      "35059/35059 [==============================] - 6s 183us/step - loss: 1047469.0182\n",
      "Epoch 40/100\n",
      "35059/35059 [==============================] - 6s 185us/step - loss: 1037001.6019\n",
      "Epoch 41/100\n",
      "35059/35059 [==============================] - 6s 184us/step - loss: 1032378.9740\n",
      "Epoch 42/100\n",
      "35059/35059 [==============================] - 6s 181us/step - loss: 1017575.4512\n",
      "Epoch 43/100\n",
      "35059/35059 [==============================] - 6s 185us/step - loss: 1007326.9029\n",
      "Epoch 44/100\n",
      "35059/35059 [==============================] - 7s 187us/step - loss: 997758.6717\n",
      "Epoch 45/100\n",
      "35059/35059 [==============================] - 6s 180us/step - loss: 987507.7833\n",
      "Epoch 46/100\n",
      "35059/35059 [==============================] - 6s 179us/step - loss: 980137.6009\n",
      "Epoch 47/100\n",
      "35059/35059 [==============================] - 6s 182us/step - loss: 976852.6883\n",
      "Epoch 48/100\n",
      "35059/35059 [==============================] - 6s 184us/step - loss: 967225.0788\n",
      "Epoch 49/100\n",
      "35059/35059 [==============================] - 6s 185us/step - loss: 962275.1364\n",
      "Epoch 50/100\n",
      "35059/35059 [==============================] - 6s 180us/step - loss: 955552.7774\n",
      "Epoch 51/100\n",
      "35059/35059 [==============================] - 6s 177us/step - loss: 951538.0734\n",
      "Epoch 52/100\n",
      "35059/35059 [==============================] - 6s 178us/step - loss: 944779.7053\n",
      "Epoch 53/100\n",
      "35059/35059 [==============================] - 6s 182us/step - loss: 943044.6612\n",
      "Epoch 54/100\n",
      "35059/35059 [==============================] - 6s 182us/step - loss: 940383.2414\n",
      "Epoch 55/100\n",
      "35059/35059 [==============================] - 6s 183us/step - loss: 934275.4859\n",
      "Epoch 56/100\n",
      "35059/35059 [==============================] - 6s 177us/step - loss: 931125.7784\n",
      "Epoch 57/100\n",
      "35059/35059 [==============================] - 6s 179us/step - loss: 926439.9915\n",
      "Epoch 58/100\n",
      "35059/35059 [==============================] - 7s 187us/step - loss: 923520.3311\n",
      "Epoch 59/100\n",
      "35059/35059 [==============================] - 6s 181us/step - loss: 921870.6342\n",
      "Epoch 60/100\n",
      "35059/35059 [==============================] - 6s 176us/step - loss: 914852.3047\n",
      "Epoch 61/100\n",
      "35059/35059 [==============================] - 6s 178us/step - loss: 909439.7046\n",
      "Epoch 62/100\n",
      "35059/35059 [==============================] - 6s 178us/step - loss: 902211.2326\n",
      "Epoch 63/100\n",
      "35059/35059 [==============================] - 6s 181us/step - loss: 900816.5790\n",
      "Epoch 64/100\n",
      "35059/35059 [==============================] - 6s 180us/step - loss: 892458.0219\n",
      "Epoch 65/100\n",
      "35059/35059 [==============================] - 6s 178us/step - loss: 889557.1648\n",
      "Epoch 66/100\n",
      "35059/35059 [==============================] - 6s 177us/step - loss: 887187.9091\n",
      "Epoch 67/100\n",
      "35059/35059 [==============================] - 6s 177us/step - loss: 883601.8530\n",
      "Epoch 68/100\n",
      "35059/35059 [==============================] - 6s 182us/step - loss: 878942.2033\n",
      "Epoch 69/100\n",
      "35059/35059 [==============================] - 6s 181us/step - loss: 876746.0538\n",
      "Epoch 70/100\n",
      "35059/35059 [==============================] - 6s 178us/step - loss: 869988.7422\n",
      "Epoch 71/100\n",
      "35059/35059 [==============================] - 6s 178us/step - loss: 867102.8447\n",
      "Epoch 72/100\n",
      "35059/35059 [==============================] - 6s 178us/step - loss: 857955.1037\n",
      "Epoch 73/100\n",
      "35059/35059 [==============================] - 6s 178us/step - loss: 851612.7574\n",
      "Epoch 74/100\n",
      "35059/35059 [==============================] - 6s 185us/step - loss: 848547.7379\n",
      "Epoch 75/100\n",
      "35059/35059 [==============================] - 7s 187us/step - loss: 834945.1443\n",
      "Epoch 76/100\n",
      "35059/35059 [==============================] - 7s 190us/step - loss: 823585.7780\n",
      "Epoch 77/100\n",
      "35059/35059 [==============================] - 6s 183us/step - loss: 811951.2088\n",
      "Epoch 78/100\n",
      "35059/35059 [==============================] - 7s 190us/step - loss: 806305.2587\n",
      "Epoch 79/100\n",
      "35059/35059 [==============================] - 6s 179us/step - loss: 798277.1180\n",
      "Epoch 80/100\n",
      "35059/35059 [==============================] - 7s 197us/step - loss: 785420.4846\n",
      "Epoch 81/100\n",
      "35059/35059 [==============================] - 7s 186us/step - loss: 779124.9038\n",
      "Epoch 82/100\n",
      "35059/35059 [==============================] - 6s 180us/step - loss: 770878.9592\n",
      "Epoch 83/100\n",
      "35059/35059 [==============================] - 6s 183us/step - loss: 765046.1451\n",
      "Epoch 84/100\n",
      "35059/35059 [==============================] - 7s 188us/step - loss: 756628.2507\n",
      "Epoch 85/100\n",
      "35059/35059 [==============================] - 6s 181us/step - loss: 750046.9387\n",
      "Epoch 86/100\n",
      "35059/35059 [==============================] - 6s 177us/step - loss: 743029.2294\n",
      "Epoch 87/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35059/35059 [==============================] - 6s 180us/step - loss: 735974.9170\n",
      "Epoch 88/100\n",
      "35059/35059 [==============================] - 6s 180us/step - loss: 733649.0561\n",
      "Epoch 89/100\n",
      "35059/35059 [==============================] - 6s 182us/step - loss: 731977.3109\n",
      "Epoch 90/100\n",
      "35059/35059 [==============================] - 6s 183us/step - loss: 717276.1389\n",
      "Epoch 91/100\n",
      "35059/35059 [==============================] - 6s 179us/step - loss: 713480.9710\n",
      "Epoch 92/100\n",
      "35059/35059 [==============================] - 6s 179us/step - loss: 707976.5097\n",
      "Epoch 93/100\n",
      "35059/35059 [==============================] - 6s 180us/step - loss: 702129.0391\n",
      "Epoch 94/100\n",
      "35059/35059 [==============================] - 6s 181us/step - loss: 701170.5715\n",
      "Epoch 95/100\n",
      "35059/35059 [==============================] - 6s 179us/step - loss: 696190.0879\n",
      "Epoch 96/100\n",
      "35059/35059 [==============================] - 6s 180us/step - loss: 691739.4411\n",
      "Epoch 97/100\n",
      "35059/35059 [==============================] - 6s 184us/step - loss: 686394.2659\n",
      "Epoch 98/100\n",
      "35059/35059 [==============================] - 6s 182us/step - loss: 686332.5235\n",
      "Epoch 99/100\n",
      "35059/35059 [==============================] - 6s 181us/step - loss: 677448.6332\n",
      "Epoch 100/100\n",
      "35059/35059 [==============================] - 6s 180us/step - loss: 676978.7532\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f9f510da790>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Crear el modelo \n",
    "model = Sequential()\n",
    "#Capa de entrada y primera capa oculta\n",
    "model.add(Dense(256, input_dim = 5, activation= \"tanh\"))\n",
    "# model.add(Dense(1))\n",
    "model.add(Activation('tanh'))\n",
    "model.add(Dropout(0.1))\n",
    "\n",
    "model.add(Dense(128))\n",
    "model.add(Activation('tanh'))\n",
    "model.add(Dropout(0.1))\n",
    "\n",
    "model.add(Dense(1))\n",
    "\n",
    "# sgd = SGD(lr=0.01, nesterov=True); NAN\n",
    "model.compile(optimizer = 'adam', loss = \"mean_squared_error\")\n",
    "\n",
    "#Entrenar con el algoritmo de back indicado \n",
    "model.fit(x_train, y_train, epochs = 100 , batch_size= 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c22dff3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "35059/35059 [==============================] - 6s 175us/step - loss: 2945286.0159\n",
      "Epoch 2/100\n",
      "35059/35059 [==============================] - 6s 170us/step - loss: 1464740.7538\n",
      "Epoch 3/100\n",
      "35059/35059 [==============================] - 6s 166us/step - loss: 1444007.8839\n",
      "Epoch 4/100\n",
      "35059/35059 [==============================] - 6s 166us/step - loss: 1426706.4507\n",
      "Epoch 5/100\n",
      "35059/35059 [==============================] - 6s 168us/step - loss: 1403211.7845\n",
      "Epoch 6/100\n",
      "35059/35059 [==============================] - 6s 165us/step - loss: 1362006.1355\n",
      "Epoch 7/100\n",
      "35059/35059 [==============================] - 6s 168us/step - loss: 1315987.1234\n",
      "Epoch 8/100\n",
      "35059/35059 [==============================] - 6s 168us/step - loss: 1263632.5573\n",
      "Epoch 9/100\n",
      "35059/35059 [==============================] - 6s 167us/step - loss: 1233945.2137\n",
      "Epoch 10/100\n",
      "35059/35059 [==============================] - 6s 166us/step - loss: 1208859.7537\n",
      "Epoch 11/100\n",
      "35059/35059 [==============================] - 6s 168us/step - loss: 1199505.8882\n",
      "Epoch 12/100\n",
      "35059/35059 [==============================] - 6s 166us/step - loss: 1186264.8818\n",
      "Epoch 13/100\n",
      "35059/35059 [==============================] - 6s 168us/step - loss: 1180231.5415\n",
      "Epoch 14/100\n",
      "35059/35059 [==============================] - 6s 169us/step - loss: 1164157.7345\n",
      "Epoch 15/100\n",
      "35059/35059 [==============================] - 6s 168us/step - loss: 1146785.3105\n",
      "Epoch 16/100\n",
      "35059/35059 [==============================] - 6s 169us/step - loss: 1127147.4530\n",
      "Epoch 17/100\n",
      "35059/35059 [==============================] - 6s 166us/step - loss: 1117390.3380\n",
      "Epoch 18/100\n",
      "35059/35059 [==============================] - 6s 166us/step - loss: 1097144.6330\n",
      "Epoch 19/100\n",
      "35059/35059 [==============================] - 6s 168us/step - loss: 1084569.0316\n",
      "Epoch 20/100\n",
      "35059/35059 [==============================] - 6s 167us/step - loss: 1073223.1534\n",
      "Epoch 21/100\n",
      "35059/35059 [==============================] - 6s 166us/step - loss: 1061257.7854\n",
      "Epoch 22/100\n",
      "35059/35059 [==============================] - 6s 166us/step - loss: 1055741.8368\n",
      "Epoch 23/100\n",
      "35059/35059 [==============================] - 6s 169us/step - loss: 1037709.1624\n",
      "Epoch 24/100\n",
      "35059/35059 [==============================] - 6s 166us/step - loss: 1028704.4123\n",
      "Epoch 25/100\n",
      "35059/35059 [==============================] - 6s 166us/step - loss: 1015329.2870\n",
      "Epoch 26/100\n",
      "35059/35059 [==============================] - 6s 170us/step - loss: 1008159.6377\n",
      "Epoch 27/100\n",
      "35059/35059 [==============================] - 6s 166us/step - loss: 990816.8398\n",
      "Epoch 28/100\n",
      "35059/35059 [==============================] - 6s 165us/step - loss: 976563.6808\n",
      "Epoch 29/100\n",
      "35059/35059 [==============================] - 6s 166us/step - loss: 964069.0014\n",
      "Epoch 30/100\n",
      "35059/35059 [==============================] - 6s 168us/step - loss: 948339.7162\n",
      "Epoch 31/100\n",
      "35059/35059 [==============================] - 6s 171us/step - loss: 932846.9754\n",
      "Epoch 32/100\n",
      "35059/35059 [==============================] - 7s 188us/step - loss: 922903.0805\n",
      "Epoch 33/100\n",
      "35059/35059 [==============================] - 6s 166us/step - loss: 908723.3069\n",
      "Epoch 34/100\n",
      "35059/35059 [==============================] - 6s 166us/step - loss: 892382.2524\n",
      "Epoch 35/100\n",
      "35059/35059 [==============================] - 6s 167us/step - loss: 880755.0933\n",
      "Epoch 36/100\n",
      "35059/35059 [==============================] - 6s 167us/step - loss: 873285.2351\n",
      "Epoch 37/100\n",
      "35059/35059 [==============================] - 6s 165us/step - loss: 865432.6358\n",
      "Epoch 38/100\n",
      "35059/35059 [==============================] - 6s 166us/step - loss: 855131.5844\n",
      "Epoch 39/100\n",
      "35059/35059 [==============================] - 6s 169us/step - loss: 847180.9593\n",
      "Epoch 40/100\n",
      "35059/35059 [==============================] - 6s 166us/step - loss: 845564.2892\n",
      "Epoch 41/100\n",
      "35059/35059 [==============================] - 6s 166us/step - loss: 827571.0466\n",
      "Epoch 42/100\n",
      "35059/35059 [==============================] - 6s 167us/step - loss: 822979.6262\n",
      "Epoch 43/100\n",
      "35059/35059 [==============================] - 6s 167us/step - loss: 819656.8464\n",
      "Epoch 44/100\n",
      "35059/35059 [==============================] - 6s 167us/step - loss: 814370.6581\n",
      "Epoch 45/100\n",
      "35059/35059 [==============================] - 6s 166us/step - loss: 806574.7446\n",
      "Epoch 46/100\n",
      "35059/35059 [==============================] - 6s 167us/step - loss: 792043.8070\n",
      "Epoch 47/100\n",
      "35059/35059 [==============================] - 6s 167us/step - loss: 801294.5336\n",
      "Epoch 48/100\n",
      "35059/35059 [==============================] - 6s 166us/step - loss: 787820.4333\n",
      "Epoch 49/100\n",
      "35059/35059 [==============================] - 6s 166us/step - loss: 784565.3071\n",
      "Epoch 50/100\n",
      "35059/35059 [==============================] - 6s 167us/step - loss: 775575.6335\n",
      "Epoch 51/100\n",
      "35059/35059 [==============================] - 6s 166us/step - loss: 766857.9895\n",
      "Epoch 52/100\n",
      "35059/35059 [==============================] - 6s 167us/step - loss: 762697.7116\n",
      "Epoch 53/100\n",
      "35059/35059 [==============================] - 6s 167us/step - loss: 757203.8117\n",
      "Epoch 54/100\n",
      "35059/35059 [==============================] - 6s 167us/step - loss: 752881.7023\n",
      "Epoch 55/100\n",
      "35059/35059 [==============================] - 6s 168us/step - loss: 748117.8765\n",
      "Epoch 56/100\n",
      "35059/35059 [==============================] - 6s 166us/step - loss: 744821.6522\n",
      "Epoch 57/100\n",
      "35059/35059 [==============================] - 6s 168us/step - loss: 731707.4701\n",
      "Epoch 58/100\n",
      "35059/35059 [==============================] - 6s 166us/step - loss: 733538.1933\n",
      "Epoch 59/100\n",
      "35059/35059 [==============================] - 6s 165us/step - loss: 733452.3033\n",
      "Epoch 60/100\n",
      "35059/35059 [==============================] - 6s 169us/step - loss: 727746.8731\n",
      "Epoch 61/100\n",
      "35059/35059 [==============================] - 9s 251us/step - loss: 729779.2195\n",
      "Epoch 62/100\n",
      "35059/35059 [==============================] - 7s 204us/step - loss: 723130.7648\n",
      "Epoch 63/100\n",
      "35059/35059 [==============================] - 7s 200us/step - loss: 719307.0258\n",
      "Epoch 64/100\n",
      "35059/35059 [==============================] - 7s 203us/step - loss: 713629.7513\n",
      "Epoch 65/100\n",
      "35059/35059 [==============================] - 7s 200us/step - loss: 720395.7730\n",
      "Epoch 66/100\n",
      "35059/35059 [==============================] - 7s 203us/step - loss: 711927.0495\n",
      "Epoch 67/100\n",
      "35059/35059 [==============================] - 7s 213us/step - loss: 711184.6620\n",
      "Epoch 68/100\n",
      "35059/35059 [==============================] - 7s 196us/step - loss: 709100.1540\n",
      "Epoch 69/100\n",
      "35059/35059 [==============================] - 7s 207us/step - loss: 698908.6273\n",
      "Epoch 70/100\n",
      "35059/35059 [==============================] - 7s 213us/step - loss: 700639.3916\n",
      "Epoch 71/100\n",
      "35059/35059 [==============================] - 7s 194us/step - loss: 695824.9147\n",
      "Epoch 72/100\n",
      "35059/35059 [==============================] - 7s 207us/step - loss: 698287.0564\n",
      "Epoch 73/100\n",
      "35059/35059 [==============================] - 7s 205us/step - loss: 695415.4912\n",
      "Epoch 74/100\n",
      "35059/35059 [==============================] - 7s 203us/step - loss: 691928.4311\n",
      "Epoch 75/100\n",
      "35059/35059 [==============================] - 7s 203us/step - loss: 690651.2346\n",
      "Epoch 76/100\n",
      "35059/35059 [==============================] - 7s 209us/step - loss: 686442.5649\n",
      "Epoch 77/100\n",
      "35059/35059 [==============================] - 8s 215us/step - loss: 691721.2950\n",
      "Epoch 78/100\n",
      "35059/35059 [==============================] - 7s 207us/step - loss: 685447.7428\n",
      "Epoch 79/100\n",
      "35059/35059 [==============================] - 7s 205us/step - loss: 683363.8454\n",
      "Epoch 80/100\n",
      "35059/35059 [==============================] - 7s 192us/step - loss: 684140.5146\n",
      "Epoch 81/100\n",
      "35059/35059 [==============================] - 7s 205us/step - loss: 675507.6696\n",
      "Epoch 82/100\n",
      "35059/35059 [==============================] - 7s 203us/step - loss: 677923.6118\n",
      "Epoch 83/100\n",
      "35059/35059 [==============================] - 7s 202us/step - loss: 680834.7432\n",
      "Epoch 84/100\n",
      "35059/35059 [==============================] - 7s 195us/step - loss: 672145.6204\n",
      "Epoch 85/100\n",
      "35059/35059 [==============================] - 7s 202us/step - loss: 674750.7262\n",
      "Epoch 86/100\n",
      "35059/35059 [==============================] - 7s 196us/step - loss: 670999.7832\n",
      "Epoch 87/100\n",
      "35059/35059 [==============================] - 7s 206us/step - loss: 676679.8003\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 88/100\n",
      "35059/35059 [==============================] - 7s 196us/step - loss: 672963.3903\n",
      "Epoch 89/100\n",
      "35059/35059 [==============================] - 7s 205us/step - loss: 674387.0627\n",
      "Epoch 90/100\n",
      "35059/35059 [==============================] - 7s 194us/step - loss: 670572.3074\n",
      "Epoch 91/100\n",
      "35059/35059 [==============================] - 7s 212us/step - loss: 666438.8978\n",
      "Epoch 92/100\n",
      "35059/35059 [==============================] - 7s 210us/step - loss: 664438.7662\n",
      "Epoch 93/100\n",
      "35059/35059 [==============================] - 7s 196us/step - loss: 665723.9432\n",
      "Epoch 94/100\n",
      "35059/35059 [==============================] - 7s 201us/step - loss: 659031.8777\n",
      "Epoch 95/100\n",
      "35059/35059 [==============================] - 7s 210us/step - loss: 666274.6585\n",
      "Epoch 96/100\n",
      "35059/35059 [==============================] - 8s 216us/step - loss: 669922.4074\n",
      "Epoch 97/100\n",
      "35059/35059 [==============================] - 7s 212us/step - loss: 666092.1712\n",
      "Epoch 98/100\n",
      "35059/35059 [==============================] - 7s 199us/step - loss: 661626.3508\n",
      "Epoch 99/100\n",
      "35059/35059 [==============================] - 7s 199us/step - loss: 664656.0019\n",
      "Epoch 100/100\n",
      "35059/35059 [==============================] - 8s 218us/step - loss: 657427.4888\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f9f515af890>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Crear el modelo \n",
    "model = Sequential()\n",
    "#Capa de entrada y primera capa oculta\n",
    "model.add(Dense(256, input_dim = 5, activation= \"relu\"))\n",
    "# model.add(Dense(1))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.1))\n",
    "\n",
    "model.add(Dense(128))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.1))\n",
    "\n",
    "model.add(Dense(1))\n",
    "\n",
    "# sgd = SGD(lr=0.01, nesterov=True); NAN\n",
    "model.compile(optimizer = 'adam', loss = \"mean_squared_error\")\n",
    "\n",
    "#Entrenar con el algoritmo de back indicado \n",
    "model.fit(x_train, y_train, epochs = 100 , batch_size= 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "efeb43c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing \n",
    "y_pred = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2f578612",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plt.plot(y_test, color='red', label='Datos reales')\n",
    "plt.plot(y_pred, color='blue', label= 'Datos prediccion')\n",
    "plt.title('Predicción')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9eecdb05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8268     2000.0\n",
       "18492    2400.0\n",
       "35305    2100.0\n",
       "15189    4400.0\n",
       "13225    4000.0\n",
       "          ...  \n",
       "18747    2000.0\n",
       "4697     3600.0\n",
       "31882    4100.0\n",
       "37915    2400.0\n",
       "2998     3200.0\n",
       "Name: KW-H, Length: 8765, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9aa6c1f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
